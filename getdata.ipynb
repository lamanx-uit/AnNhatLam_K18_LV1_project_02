{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64370a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as req\n",
    "import json\n",
    "import time\n",
    "import openpyxl as px\n",
    "import html\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import threading\n",
    "import queue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b06e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('products-0-200000.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e1cb787",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ids = df['id'].tolist()  # list product ID\n",
    "\n",
    "headers = {\n",
    "        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',\n",
    "        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,image/apng,*/*;q=0.8,application/signed-exchange;v=b3;q=0.7',\n",
    "        'Accept-Language': 'en-US,en;q=0.9,fr-FR;q=0.8,fr;q=0.7,vi;q=0.6',\n",
    "        'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "        'Cache-Control': 'max-age=0',\n",
    "        'Sec-Ch-Ua': '\"Not)A;Brand\";v=\"8\", \"Chromium\";v=\"138\", \"Google Chrome\";v=\"138\"',\n",
    "        'Sec-Ch-Ua-Mobile': '?0',\n",
    "        'Sec-Ch-Ua-Platform': '\"Windows\"',\n",
    "        'Sec-Fetch-Dest': 'document',\n",
    "        'Sec-Fetch-Mode': 'navigate',\n",
    "        'Sec-Fetch-Site': 'none',\n",
    "        'Sec-Fetch-User': '?1',\n",
    "        'Upgrade-Insecure-Requests': '1'\n",
    "    }\n",
    "    \n",
    "\"\"\"DoD: Sử dụng code Python, tải về thông tin của 200k sản phẩm (list product id bên dưới) của Tiki và lưu thành các file .json. \n",
    "Mỗi file có thông tin của khoảng 1000 sản phẩm. \n",
    "Các thông in cần lấy bao gồm: id, name, url_key, price, description, images url. \n",
    "Yêu cầu chuẩn hoá nội dung trong \"description\" và tìm phương án rút ngắn thời gian lấy dữ liệu.\n",
    "- List product_id: https://1drv.ms/u/s!AukvlU4z92FZgp4xIlzQ4giHVa5Lpw?e=qDXctn\n",
    "- API get product detail: https://api.tiki.vn/product-detail/api/v1/products/138083218\"\"\"\n",
    "\n",
    "session = req.Session()\n",
    "max_retries = 3\n",
    "\n",
    "def get_product_data(product_id):\n",
    "    url = f'https://api.tiki.vn/product-detail/api/v1/products/{product_id}'\n",
    "    print(f\"Fetching data for product ID {product_id}\")\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        response = session.get(url, headers=headers, timeout=10)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            selected_data = {\n",
    "                'id': data['id'],\n",
    "                'name': data['name'], \n",
    "                'url_key': data['url_key'],\n",
    "                'price': data['price'],\n",
    "                'description': data['description'],\n",
    "                'images_url': data['images']  \n",
    "            }\n",
    "            # q.put(selected_data)\n",
    "            print(f\"Fetched data for product ID {product_id}\")\n",
    "            # Preprocess the description\n",
    "            text = selected_data['description']\n",
    "            if text:\n",
    "                text = html.unescape(text)\n",
    "                text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "                text = re.sub(r'\\s+', ' ', text).strip()\n",
    "                text = text.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "            else:\n",
    "                text = \"\" \n",
    "            selected_data['description'] = text\n",
    "            print(f\"Processed data for {product_id} \\n\")\n",
    "            return selected_data\n",
    "        \n",
    "        elif response.status_code in [429, 500]:\n",
    "            print(f\"Rate limit exceeded for product ID {product_id}, retrying...\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(2 ** attempt) \n",
    "                \n",
    "        else:\n",
    "            print(f\"Error fetching data for product ID {product_id}: {response.status_code}\")\n",
    "            return None \n",
    "        \n",
    "    print(f\"Failed to fetch data for product ID {product_id} after {max_retries} attempts\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be21a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    # data = q_in.get()\n",
    "    text = data['description']\n",
    "    \n",
    "    if text:\n",
    "        # Remove HTML tags and decode HTML entities\n",
    "        text = html.unescape(text)\n",
    "        text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "        \n",
    "        # surrogate characters\n",
    "        text = text.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "    else:\n",
    "        text = \"\"\n",
    "    \n",
    "    data['description'] = text\n",
    "    # q_out.put(data)\n",
    "    print(f\"Preprocessed data for {data['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dec5c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving(data, batch_number):\n",
    "\n",
    "    json_string = json.dumps(data, ensure_ascii=False, indent=4)\n",
    "\n",
    "    filename = f\"batches_test/batch_{batch_number}.json\"  \n",
    "    with open(filename, 'w', encoding='utf-8', errors='ignore') as f:\n",
    "        f.write(json_string)\n",
    "        \n",
    "    print(f\"Saved batch {batch_number} to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ba3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ThreadPoolExecutor for better performance\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def get_product_data_wrapper(product_id):\n",
    "    total_products = 0\n",
    "    batch_size = 1000  # Number of products per batch\n",
    "    batch_total = len(product_ids)[:2000]  # Total number of products to process\n",
    "\n",
    "    for batches in range(0, batch_total, batch_size):\n",
    "        batch_ids = product_ids[batches:batches + batch_size]\n",
    "        future = []\n",
    "        data = []\n",
    "        with ThreadPoolExecutor(max_workers=50) as executor:\n",
    "            for product_id in batch_ids:\n",
    "                future.append(executor.submit(get_product_data, product_id))\n",
    "        # Collect results\n",
    "        for f in future:\n",
    "            data.append(f.result())\n",
    "        # Filter out None results\n",
    "        data = [d for d in data if d is not None]\n",
    "        total_products += len(data)\n",
    "        print(f\"Total products fetched in this batch: {len(data)} / {batch_size}\")\n",
    "        print(f\"Batch {batches // batch_size + 1} fetched with {len(data)} products.\")\n",
    "        \n",
    "        # Process the result and save it\n",
    "        saving(data, batches // batch_size + 1)\n",
    "        print(f\"Batch {batches // batch_size + 1} processed and saved.\")\n",
    "\n",
    "    print(f\"Total products collected for this batch: {total_products} / {batch_total}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_product_data_wrapper(product_ids)\n",
    "    print(\"All batches processed and saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e7129a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batching():\n",
    "    max_threads = 50\n",
    "    total_files = 0\n",
    "\n",
    "    for i in range(0, 1000, 1000):\n",
    "        batch = product_id[i:i+1000]\n",
    "        batch_number = i // 1000 + 1\n",
    "        print(f\"Processing batch {batch_number}\")\n",
    "\n",
    "        thread = []\n",
    "        for single_product in batch:\n",
    "            if len(thread) >= max_threads:\n",
    "                for t in thread:\n",
    "                    t.join()\n",
    "                thread.clear()\n",
    "            t1 = threading.Thread(target=get_product_data, args=(single_product, data_queue))\n",
    "            t1.start()\n",
    "            thread.append(t1)\n",
    "            \n",
    "        for t in thread:\n",
    "            t.join()\n",
    "            \n",
    "        preprocessing_threads = []\n",
    "        while not data_queue.empty():\n",
    "            t2 = threading.Thread(target=preprocessing, args=(data_queue, result_queue))\n",
    "            t2.start()\n",
    "            preprocessing_threads.append(t2)\n",
    "        \n",
    "        for t in preprocessing_threads:\n",
    "            t.join()\n",
    "            \n",
    "        print(f\"Preprocessing done, now saving...\")\n",
    "        \n",
    "        current_batch_count = result_queue.qsize()\n",
    "\n",
    "        saving(result_queue, batch_number)\n",
    "        \n",
    "        total_files += current_batch_count\n",
    "        print(f\"Total products processed so far: {total_files}\")\n",
    "\n",
    "    print(f\"\\nTotal products processed: {total_files}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEC_lab2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
