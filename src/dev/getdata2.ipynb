{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64370a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as req\n",
    "import json\n",
    "import time\n",
    "import openpyxl as px\n",
    "import html\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "import threading\n",
    "import queue\n",
    "from requests.adapters import HTTPAdapter\n",
    "import os\n",
    "import random\n",
    "import logging\n",
    "from pathlib import Path\n",
    "\n",
    "BASE_DIR = Path(os.getcwd()).resolve().parent.parent\n",
    "FILES = {\n",
    "    'products': BASE_DIR / 'data' / 'input' / 'products-0-200000.xlsx',\n",
    "    'logs': BASE_DIR / 'tests' / 'logs' / 'crawl.log',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "82c21423",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_logging():\n",
    "    logging.basicConfig(\n",
    "        filename=FILES['logs'],\n",
    "        level=logging.INFO,\n",
    "        format='%(asctime)s - %(levelname)s: %(message)s',\n",
    "        datefmt='%Y-%m-%d %H:%M:%S'\n",
    "    )\n",
    "    logging.info(\"Logging setup complete.\")\n",
    "    \n",
    "    \n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "984c1115",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data():\n",
    "    \"\"\"Read product IDs, check and improve veracity.\"\"\"\n",
    "    # Read the Excel file\n",
    "    df = pd.read_excel(FILES['products'])\n",
    "    logging.info(f\"Read input file successfully\")\n",
    "    \n",
    "    product_ids = df['id'].tolist()  # list product IDs\n",
    "    logging.info(f\"Extracted {len(product_ids)} product IDs from the input file\")\n",
    "\n",
    "    product_ids = dict.fromkeys(product_ids)  # remove duplicates\n",
    "    logging.info(f\"Removed duplicates successfully, {len(product_ids)} unique product IDs remaining\")\n",
    "    product_ids = list(product_ids.keys())  \n",
    "    \n",
    "    # Ensure product IDs are in appropriate format\n",
    "    valid_ids = []\n",
    "    invalid_count = 0\n",
    "    for pid in product_ids:\n",
    "       if isinstance(pid, (int, float)) and str(int(pid)).isdigit() and pid > 0 and pid == int(pid):\n",
    "           valid_ids.append(int(pid))\n",
    "       else:\n",
    "           invalid_count += 1\n",
    "           logging.warning(f\"Invalid product ID found: {pid} (type: {type(pid)})\")\n",
    "    logging.info(f\"Validation complete: {len(valid_ids)} valid IDs, {invalid_count} invalid IDs removed\")\n",
    "    product_ids = valid_ids\n",
    "    return product_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f250af57",
   "metadata": {},
   "outputs": [],
   "source": [
    "read_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b06e2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_excel('/home/lamanx/DEC/Lab2/data/input/products-0-200000.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a95593b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         False\n",
       "1         False\n",
       "2         False\n",
       "3         False\n",
       "4         False\n",
       "          ...  \n",
       "199995    False\n",
       "199996    False\n",
       "199997    False\n",
       "199998    False\n",
       "199999    False\n",
       "Name: id, Length: 200000, dtype: bool"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['id'].duplicated()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8683ae91",
   "metadata": {},
   "outputs": [],
   "source": [
    "product_ids = df['id'].tolist()  # list product ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e1cb787",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = {\n",
    "    'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/138.0.0.0 Safari/537.36',\n",
    "    'Accept': 'application/json, */*',\n",
    "    'Accept-Language': 'en-US,en;q=0.9,fr-FR;q=0.8,fr;q=0.7,vi;q=0.6',\n",
    "    'Accept-Encoding': 'gzip, deflate, br, zstd',\n",
    "    'Sec-Ch-Ua': '\"Not)A;Brand\";v=\"8\", \"Chromium\";v=\"138\", \"Google Chrome\";v=\"138\"',\n",
    "    'Sec-Ch-Ua-Mobile': '?0',\n",
    "    'Sec-Ch-Ua-Platform': '\"Windows\"',\n",
    "    'Referer': 'https://tiki.vn/',\n",
    "    'Origin': 'https://tiki.vn'\n",
    "}\n",
    "    \n",
    "\"\"\"DoD: Sử dụng code Python, tải về thông tin của 200k sản phẩm (list product id bên dưới) của Tiki và lưu thành các file .json. \n",
    "Mỗi file có thông tin của khoảng 1000 sản phẩm. \n",
    "Các thông in cần lấy bao gồm: id, name, url_key, price, description, images url. \n",
    "Yêu cầu chuẩn hoá nội dung trong \"description\" và tìm phương án rút ngắn thời gian lấy dữ liệu.\n",
    "- List product_id: https://1drv.ms/u/s!AukvlU4z92FZgp4xIlzQ4giHVa5Lpw?e=qDXctn\n",
    "- API get product detail: https://api.tiki.vn/product-detail/api/v1/products/138083218\"\"\"\n",
    "\n",
    "session = req.Session()\n",
    "session.mount('https://', HTTPAdapter(\n",
    "    pool_connections=100,\n",
    "    pool_maxsize=100\n",
    "))\n",
    "max_retries = 3  # Base delay in seconds\n",
    "\n",
    "def get_product_data(product_id, max_retries=3):\n",
    "    url = f'https://api.tiki.vn/product-detail/api/v1/products/{product_id}'\n",
    "    print(f\"Fetching data for product ID {product_id}\")\n",
    "    \n",
    "    for attempt in range(max_retries):\n",
    "        base_delay = 2 * attempt  \n",
    "        response = session.get(url, headers=headers, timeout=20)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            selected_data = {\n",
    "                'id': data['id'],\n",
    "                'name': data['name'], \n",
    "                'url_key': data['url_key'],\n",
    "                'price': data['price'],\n",
    "                'description': data['description'],\n",
    "                'images_url': data['images']  \n",
    "            }\n",
    "            print(f\"Fetched data for product ID {product_id}\")\n",
    "            return selected_data\n",
    "        \n",
    "        elif response.status_code in [429, 500]:\n",
    "            print(f\"Rate limit exceeded for product ID {product_id}, retrying...\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(random.uniform(1, 3)) \n",
    "                \n",
    "        else:\n",
    "            print(f\"Error fetching data for product ID {product_id}: {response.status_code}, retrying...\")\n",
    "            if attempt < max_retries - 1:\n",
    "                time.sleep(random.uniform(1, 3)) \n",
    "            return None\n",
    "        \n",
    "    print(f\"Failed to fetch data for product ID {product_id} after {max_retries} attempts\")\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c2680d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_retry():\n",
    "    for attempt in range(3):\n",
    "        print(f\"Attempt {attempt}\")\n",
    "\n",
    "        # Giả sử luôn gặp lỗi 404\n",
    "        status_code = 404\n",
    "        \n",
    "        if status_code == 200:\n",
    "            return \"Success\"\n",
    "        elif status_code in [429, 500]:\n",
    "            print(\"429/500 case\")\n",
    "            if attempt < 2:\n",
    "                time.sleep(1)\n",
    "        else:\n",
    "            print(\"Other error case\")  \n",
    "            if attempt < 2:\n",
    "                time.sleep(1)\n",
    "    \n",
    "    return None\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Test the retry logic\n",
    "    result = test_retry()\n",
    "    print(f\"Test result: {result}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be21a66",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(data):\n",
    "    text = data['description']\n",
    "    \n",
    "    if text:\n",
    "        # Remove HTML tags and decode HTML entities\n",
    "        text = html.unescape(text)\n",
    "        text = BeautifulSoup(text, 'html.parser').get_text()\n",
    "        text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "        # surrogate characters\n",
    "        text = text.encode('utf-8', errors='ignore').decode('utf-8')\n",
    "    else:\n",
    "        text = \"\"\n",
    "    \n",
    "    data['description'] = text\n",
    "    print(f\"Preprocessed data for {data['id']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dec5c574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def saving(data, batch_number):\n",
    "\n",
    "    json_string = json.dumps(data, ensure_ascii=False, indent=4)\n",
    "\n",
    "    filename = f\"batches_test/batch_{batch_number}.json\"  \n",
    "    with open(filename, 'w', encoding='utf-8', errors='ignore') as f:\n",
    "        f.write(json_string)\n",
    "        \n",
    "    print(f\"Saved batch {batch_number} to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ba3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ThreadPoolExecutor for better performance\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "def get_product_data_wrapper(product_id):\n",
    "    total_products = 0\n",
    "    batch_size = 1000  # Number of products per batch\n",
    "    batch_total = len(product_ids[:2000])  # Total number of products to process\n",
    "\n",
    "    for batches in range(0, batch_total, batch_size):\n",
    "        batch_ids = product_ids[batches:batches + batch_size]\n",
    "        future = []\n",
    "        data = []\n",
    "        with ThreadPoolExecutor(max_workers=20) as executor:\n",
    "            for product_id in batch_ids:\n",
    "                future.append(executor.submit(get_product_data, product_id))\n",
    "        # Collect results\n",
    "        for f in future:\n",
    "            data.append(f.result())\n",
    "        # Filter out None results\n",
    "        data = [d for d in data if d is not None]\n",
    "        total_products += len(data)\n",
    "        print(f\"Total products fetched in this batch: {len(data)} / {batch_size}\")\n",
    "        print(f\"Batch {batches // batch_size + 1} fetched with {len(data)} products.\")\n",
    "        \n",
    "        # Process the result\n",
    "        for item in data:\n",
    "            preprocessing(item)\n",
    "        \n",
    "        # Process the result and save it\n",
    "        saving(data, batches // batch_size + 1)\n",
    "        print(f\"Batch {batches // batch_size + 1} processed and saved.\")\n",
    "\n",
    "    print(f\"Total products collected for this batch: {total_products} / {batch_total}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    get_product_data_wrapper(product_ids)\n",
    "    print(\"All batches processed and saved.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DEC_lab2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
